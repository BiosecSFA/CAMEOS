import os
#If you don't want to use GPU, uncomment this line.
#os.environ["CUDA_VISIBLE_DEVICES"] = ""

import tensorflow as tf
import numpy as np

import random

def genes_to_array(gene_list):
	zero_mat = np.zeros([len(gene_list), len(gene_list[0])])
	#aa_to_int = {'.': 0, 'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5, 'Q': 6, 'E': 7, 'G': 8, 'H': 9, 'I': 10,
	#	'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15, 'S': 16, 'T': 17, 'W': 18, 'Y': 19, 'V': 20, '-': 21, 'X': 21, '*': 21}
	aa_to_int = {'.': 30, 'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19, '-': 20, 'X': 20, '*': 20}
	numeric_seq = [[aa_to_int[aa] for aa in prot] for prot in gene_list]
	return np.asarray(numeric_seq)

def energy_calc(prot_mat, w1, w2, mask):
	prot_mask = prot_mat * mask
	skinny = tf.matmul(prot_mask, w1)
	nprot_nres = tf.matmul(prot_mask, w2)
	final = tf.matmul(tf.expand_dims(nprot_nres, [1]), tf.expand_dims(prot_mat, [2]))

	return tf.squeeze(skinny, [1]) + tf.squeeze(final, [1, 2])

def one_hot(x):
	encoded = tf.one_hot(tf.cast(x, tf.int32), depth = 21, dtype = tf.float32)
	return tf.reshape(encoded, [x.shape[0], -1])

def mask_reader(prot_len, window_len):
	for pos in range(0, prot_len - (window_len - 1)):
		yield pos, np.pad(np.ones(21 * window_len), [[21 * pos, 21 * (prot_len - (window_len + pos))]], "constant")

def local_energy_calcs(core_name, gene_w1, gene_w2, msa_fa, window_lens):
	tf.reset_default_graph()
	with tf.Session() as sess:

		w1 = np.load(gene_w1)
		w2 = np.load(gene_w2)

		align_fa = open(msa_fa)
		align_read = align_fa.readlines()
		align_fa.close()

		prot_len = len(align_read[1].strip())

		list_of_genes = []
		mask_input = []
		for line in align_read:
			if line[0] == ">":
				continue
			else:
				if not ("B" in line or "J" in line or "O" in line or "U" in line or "Z" in line):
					#mask_input.append('.' + line.strip()[1:7] + '.' * (len(line.strip()) - 7))
					list_of_genes.append(line.strip())

		random.shuffle(list_of_genes)
		if num_to_examine is not None and type(num_to_examine) == type(3):
			list_of_genes = list_of_genes[:num_to_examine] #Let's sample 2000 proteins to slightly speed up calculations.

		prot_mat = genes_to_array(list_of_genes)

		tf_prots = one_hot(prot_mat)
		tf_w1 = tf.cast(w1, tf.float32)
		tf_w2 = tf.cast(w2, tf.float32)
		mask_pc = tf.placeholder(tf.float32, shape=[prot_len * 21])

		energy_op = energy_calc(tf_prots, tf_w1, tf_w2, mask_pc)

		for window_len in window_lens:
			print("Starting window_len", window_len)
			full_data = []
			pos_nums = []
			for (pos_num, mask) in mask_reader(prot_len, window_len):
				full_data.append(sess.run(energy_op, feed_dict={mask_pc: mask}))
				pos_nums.append(pos_num)

			np.save("%s_window_%i.npy" %(core_name, window_len), np.stack(full_data))

		sess.close()

def main():
	gene_name = "protein" #name of gene you are examining.
	gene_w1 = gene_name + "_w1.npy" #path to w1 npy file (generated by convert_jld_to_npy.jl)
	gene_w2 = gene_name + "_w2.npy" #path to w1 npy file (generated by convert_jld_to_npy.jl)
	gene_msa = gene_name + ".msa" #multiple sequence alignment we're looking at.
	windows = [60, 70, 80, 90] #window sizes for local energy calculations.
	num_to_examine = None #leave as None if you want to check all genes, set to e.g. 2000 if you want just a subset for quick estimate.
	#Note: large alignments may max out GPU memory.
	local_energy_calcs(gene_name, gene_w1, gene_w2, gene_msa, num_to_examine = None)
	#Output: will save many npy files as protein_window_60.npy with local energies across all genes.
	#The shape will be (number_of_positions, number_of_proteins). You can plot means/std along length to get similar output as our paper.

main()
